{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The programm aims to predict the weather\n",
    "'''\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import datetime\n",
    "import pickle\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from multiprocessing import Pool\n",
    "import sys\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "import sklearn\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# 特征汇总 \n",
    "# 十个风速模型 m1..m10\n",
    "# 未来一小时十个风速模型 m1_..m10_\n",
    "# 十个风速方差，均值，最大值，最小值\n",
    "# 小时 h\n",
    "\n",
    "# 对未来天气进行初步预测 ####################################\n",
    "def feature_selection_x(param):\n",
    "    (input_weather,day) = param\n",
    "    x_max = 548\n",
    "    y_max = 421\n",
    "    train_x = np.zeros((4152744, 129),dtype=np.float16)\n",
    "    i = 0\n",
    "    for h in tqdm(range(3,21)):\n",
    "        for x in range(x_max):\n",
    "            for y in range(y_max):\n",
    "                temp = []\n",
    "                # now weather\n",
    "                temp_1 = []\n",
    "                temp_1_wind = []\n",
    "                for mod in range(1, 11):\n",
    "                    temp_1_wind.append(input_weather[str(mod)][str(day)][str(h)][0,x,y])\n",
    "                \n",
    "                mean = np.mean(temp_1_wind)\n",
    "                var = np.var(temp_1_wind)\n",
    "                max_wind = np.max(temp_1_wind)\n",
    "                min_wind = np.min(temp_1_wind)\n",
    "                basic_wind_1 = [mean,var,max_wind,min_wind]\n",
    "                #temp_1_wind.extend([mean,var,max_wind,min_wind])\n",
    "\n",
    "                temp_1_rainfall = []\n",
    "                for mod in range(1, 11):\n",
    "                    temp_1_rainfall.append(input_weather[str(mod)][str(day)][str(h)][1,x,y])\n",
    "                mean = np.mean(temp_1_rainfall)\n",
    "                var = np.var(temp_1_rainfall)\n",
    "                max_wind = np.max(temp_1_rainfall)\n",
    "                min_wind = np.min(temp_1_rainfall)\n",
    "                basic_rainfall_1 = [mean,var,max_wind,min_wind]\n",
    "\n",
    "                temp_1.extend(temp_1_wind)\n",
    "                temp_1.extend(basic_wind_1)\n",
    "                temp_1.extend(temp_1_rainfall)\n",
    "                temp_1.extend(basic_rainfall_1)\n",
    "                # next hour weather\n",
    "                temp_2 = []\n",
    "                temp_2_wind = []\n",
    "                for mod in range(1, 11):\n",
    "                    try:\n",
    "                        temp_2_wind.append(input_weather[str(mod)][str(day)][str(h+1)][0,x,y])\n",
    "                    except:\n",
    "                        temp_2_wind.append(input_weather[str(mod)][str(day)][str(h)][0,x,y])\n",
    "                mean = np.mean(temp_2_wind)\n",
    "                var = np.var(temp_2_wind)\n",
    "                max_wind = np.max(temp_2_wind)\n",
    "                min_wind = np.min(temp_2_wind)\n",
    "                basic_wind_2 = [mean,var,max_wind,min_wind]\n",
    "\n",
    "                #temp_2_wind.extend([mean,var,max_wind,min_wind])\n",
    "                \n",
    "                temp_2_rainfall = []\n",
    "                for mod in range(1, 11):\n",
    "                    try:\n",
    "                        temp_2_rainfall.append(input_weather[str(mod)][str(day)][str(h+1)][1,x,y])\n",
    "                    except:\n",
    "                        temp_2_rainfall.append(input_weather[str(mod)][str(day)][str(h)][1,x,y])\n",
    "                mean = np.mean(temp_2_rainfall)\n",
    "                var = np.var(temp_2_rainfall)\n",
    "                max_wind = np.max(temp_2_rainfall)\n",
    "                min_wind = np.min(temp_2_rainfall)\n",
    "                basic_rainfall_2 = [mean,var,max_wind,min_wind]\n",
    "\n",
    "                #temp_2_rainfall.extend([mean,var,max_wind,min_wind])\n",
    "\n",
    "                temp_2.extend(temp_2_wind)\n",
    "                temp_2.extend(basic_wind_2)\n",
    "                temp_2.extend(temp_2_rainfall)\n",
    "                temp_2.extend(basic_rainfall_2)\n",
    "\n",
    "                # last hour weather\n",
    "                temp_3 = []\n",
    "                temp_3_wind = []\n",
    "                for mod in range(1, 11):\n",
    "                    try:\n",
    "                        temp_3_wind.append(input_weather[str(mod)][str(day)][str(h-1)][0,x,y])\n",
    "                    except:\n",
    "                        temp_3_wind.append(input_weather[str(mod)][str(day)][str(h)][0,x,y])\n",
    "                mean = np.mean(temp_3_wind)\n",
    "                var = np.var(temp_3_wind)\n",
    "                max_wind = np.max(temp_3_wind)\n",
    "                min_wind = np.min(temp_3_wind)\n",
    "                basic_wind_3 = [mean,var,max_wind,min_wind]\n",
    "\n",
    "                temp_3_rainfall = []\n",
    "                for mod in range(1, 11):\n",
    "                    try:\n",
    "                        temp_3_rainfall.append(input_weather[str(mod)][str(day)][str(h-1)][1,x,y])\n",
    "                    except:\n",
    "                        temp_3_rainfall.append(input_weather[str(mod)][str(day)][str(h)][1,x,y])\n",
    "                mean = np.mean(temp_3_rainfall)\n",
    "                var = np.var(temp_3_rainfall)\n",
    "                max_wind = np.max(temp_3_rainfall)\n",
    "                min_wind = np.min(temp_3_rainfall)\n",
    "                basic_rainfall_3 = [mean,var,max_wind,min_wind]\n",
    "\n",
    "                temp_3.extend(temp_3_wind)\n",
    "                temp_3.extend(basic_wind_3)\n",
    "                temp_3.extend(temp_3_rainfall)\n",
    "                temp_3.extend(basic_rainfall_3)\n",
    "                \n",
    "                # add info\n",
    "                average = [basic_rainfall_2[0]-basic_rainfall_1[0],basic_rainfall_1[0]-basic_rainfall_3[0],\n",
    "                          basic_wind_2[0]-basic_wind_1[0],basic_wind_1[0]-basic_wind_3[0]]\n",
    "                add_model_1 = list(np.array(temp_2_wind)-np.array(temp_1_wind))\n",
    "                add_model_2 = list(np.array(temp_1_wind)-np.array(temp_3_wind))\n",
    "                add_model_3 = list(np.array(temp_2_rainfall)-np.array(temp_1_rainfall))\n",
    "                add_model_4 = list(np.array(temp_1_rainfall)-np.array(temp_3_rainfall))\n",
    "                \n",
    "                temp.extend(temp_1)\n",
    "                temp.extend(temp_2)\n",
    "                temp.extend(temp_3)\n",
    "                temp.extend(average)\n",
    "                temp.extend(add_model_1)\n",
    "                temp.extend(add_model_2)\n",
    "                temp.extend(add_model_3)\n",
    "                temp.extend(add_model_4)\n",
    "                # r=5 region 平均风速增长/安全面积\n",
    "                # r=10 region 平均风速增长/安全面积 \n",
    "                # r=20 region 平均风速增长/安全面积\n",
    "                # 最近的风险点的距离\n",
    "                # 风险点增长\n",
    "                # \n",
    "                temp.append(h)\n",
    "                #print(len(temp))\n",
    "                train_x[i,:] = temp\n",
    "                i += 1\n",
    "\n",
    "    # return (day,train_x)\n",
    "    return [day,train_x]\n",
    "\n",
    "\n",
    "def feature_selection_y(output_weather):\n",
    "    x_max = 548\n",
    "    y_max = 421\n",
    "    wind_y = []\n",
    "    rainfall_y = []\n",
    "    prob_y = []\n",
    "    for day in range(1,6):\n",
    "        for h in tqdm(range(3,21)):\n",
    "            for x in range(x_max):\n",
    "                for y in range(y_max):\n",
    "                    wind_y.append(output_weather[str(day)][str(h)][0,x,y])\n",
    "                    rainfall_y.append(output_weather[str(day)][str(h)][1,x,y])\n",
    "                    if output_weather[str(day)][str(h)][0,x,y]<15 and output_weather[str(day)][str(h)][1,x,y]<4:\n",
    "                        prob_y.append(1)\n",
    "                    else:\n",
    "                        prob_y.append(0)\n",
    "    return wind_y,rainfall_y,prob_y\n",
    "# 特征汇总 \n",
    "# 十个风速模型 m1..m10\n",
    "# 未来一小时十个风速模型 m1_..m10_\n",
    "# 十个风速方差，均值，最大值，最小值\n",
    "# 小时 h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "b = np.array([2,3])\n",
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data source\n",
    "input_weather = open('weather_train_1_5.pkl', 'rb')\n",
    "input_weather = pickle.load(input_weather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi proc to generate train data\n",
    "pool = Pool(3)\n",
    "params = [(input_weather,i) for i in range(1,6)]\n",
    "result = pool.map(feature_selection_x, params)\n",
    "pool.close()  # 关闭进程池，不再接受新的进程\n",
    "pool.join()  # 主进程阻塞等待子进程的退出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sorted(result,key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = np.concatenate((result[0][1],result[1][1],result[2][1],result[3][1],result[4][1]),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"layer_1_basicinfo_129.npy\", weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:18<00:00,  1.02s/it]\n",
      "100%|██████████| 18/18 [00:18<00:00,  1.03s/it]\n",
      "100%|██████████| 18/18 [00:19<00:00,  1.10s/it]\n",
      "100%|██████████| 18/18 [00:17<00:00,  1.04it/s]\n",
      "100%|██████████| 18/18 [00:18<00:00,  1.00s/it]\n"
     ]
    }
   ],
   "source": [
    "output_weather = open('weather_train_label_1_5.pkl', 'rb')\n",
    "output_weather = pickle.load(output_weather)\n",
    "wind_y,rainfall_y,prob_y = feature_selection_y(output_weather)\n",
    "#del wind_y,rainfall_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.load(\"layer_1_basicinfo_129.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用平均值预测\n",
    "sample_index = np.load('sample_index.npy')\n",
    "x_sample = np.load('./feature/layer_2_X_129.npy')\n",
    "#y_sample = np.load('./feature/layer_2_label.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sample = np.array(wind_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sample =train_x\n",
    "del train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = np.load('sample_index.npy')\n",
    "x_sample = train_x[sample_index]\n",
    "y_sample = np.array(prob_y)[sample_index]\n",
    "del train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试误差 0.610817918183\n",
      "测试误差 0.628651945814\n",
      "测试误差 0.627866566635\n",
      "测试误差 0.629099255005\n",
      "测试误差 0.62665532363\n",
      "测试误差 0.630623333217\n",
      "测试误差 0.631695952863\n",
      "测试误差 0.626688777242\n",
      "测试误差 0.629042242385\n",
      "测试误差 0.629708087361\n",
      "测试误差 0.630307579244\n",
      "测试误差 0.629629798341\n"
     ]
    }
   ],
   "source": [
    "# 回归模型，预测基本数据\n",
    "param = {\n",
    "    'num_leaves':225, \n",
    "    #'num_leaves':100, \n",
    "    'num_trees':150, \n",
    "    'objective':'regression',\n",
    "    'metric':'l2',\n",
    "    'learning_rate': 0.05,\n",
    "    'num_threads':8,\n",
    "    #'min_sum_hessian_in_leaf':100\n",
    "}\n",
    "#x_sample = train_x\n",
    "#y_sample = np.array(wind_y)\n",
    "kfolds = 12\n",
    "kf = KFold(n_splits=kfolds,shuffle=True,random_state=2016)\n",
    "result = np.zeros((len(prob_y),))\n",
    "i=0\n",
    "num_round = 130\n",
    "for train_index,test_index in kf.split(x_sample):\n",
    "    X_train, X_test = x_sample[train_index], x_sample[test_index]\n",
    "    y_train, y_test = y_sample[train_index], y_sample[test_index]\n",
    "    train_data = lgb.Dataset(X_train,label=y_train)\n",
    "    #validation_data = lgb.Dataset(X_test,label=y_test)\n",
    "    bst = lgb.train(param, train_data,num_round)\n",
    "    result[test_index] = bst.predict(X_test)\n",
    "    print('测试误差',mse(y_test,result[test_index]))\n",
    "    #nonsample_result[i,:] = bst.predict(x_nonsample)\n",
    "    file_name = 'model_1_wind_shuffle_'+str(i)+'.model'\n",
    "    bst.save_model(file_name)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存风速数据到 pickle\n",
    "i = 0\n",
    "x_max = 548\n",
    "y_max = 421\n",
    "weather = {}\n",
    "for day in range(1,6):\n",
    "    weather_h = {}\n",
    "    for h in range(3,21):\n",
    "        data = np.zeros((x_max,y_max),np.float16)\n",
    "        for x in range(x_max):\n",
    "            for y in range(y_max):\n",
    "                data[x,y] = result[i]\n",
    "                i += 1\n",
    "        weather_h[str(h)] = data\n",
    "    weather[str(day)] = weather_h\n",
    "import pickle\n",
    "f1 = open('layer_1_wind_shuffle.pkl', 'wb')\n",
    "pickle.dump(weather,f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.983407\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's auc: 0.984095\n",
      "[3]\tvalid_0's auc: 0.984567\n",
      "[4]\tvalid_0's auc: 0.984692\n",
      "[5]\tvalid_0's auc: 0.984895\n",
      "[6]\tvalid_0's auc: 0.985057\n",
      "[7]\tvalid_0's auc: 0.985122\n",
      "[8]\tvalid_0's auc: 0.985158\n",
      "[9]\tvalid_0's auc: 0.985191\n",
      "[10]\tvalid_0's auc: 0.985237\n",
      "[11]\tvalid_0's auc: 0.985307\n",
      "[12]\tvalid_0's auc: 0.98534\n",
      "[13]\tvalid_0's auc: 0.985395\n",
      "[14]\tvalid_0's auc: 0.985407\n",
      "[15]\tvalid_0's auc: 0.985464\n",
      "[16]\tvalid_0's auc: 0.985495\n",
      "[17]\tvalid_0's auc: 0.985502\n",
      "[18]\tvalid_0's auc: 0.985523\n",
      "[19]\tvalid_0's auc: 0.985553\n",
      "[20]\tvalid_0's auc: 0.985569\n",
      "[21]\tvalid_0's auc: 0.985607\n",
      "[22]\tvalid_0's auc: 0.985603\n",
      "[23]\tvalid_0's auc: 0.985609\n",
      "[24]\tvalid_0's auc: 0.985624\n",
      "[25]\tvalid_0's auc: 0.985634\n",
      "[26]\tvalid_0's auc: 0.985651\n",
      "[27]\tvalid_0's auc: 0.985675\n",
      "[28]\tvalid_0's auc: 0.985716\n",
      "[29]\tvalid_0's auc: 0.985759\n",
      "[30]\tvalid_0's auc: 0.985785\n",
      "[31]\tvalid_0's auc: 0.985787\n",
      "[32]\tvalid_0's auc: 0.985801\n",
      "[33]\tvalid_0's auc: 0.98583\n",
      "[34]\tvalid_0's auc: 0.985839\n",
      "[35]\tvalid_0's auc: 0.985845\n",
      "[36]\tvalid_0's auc: 0.985863\n",
      "[37]\tvalid_0's auc: 0.985889\n",
      "[38]\tvalid_0's auc: 0.985892\n",
      "[39]\tvalid_0's auc: 0.985898\n",
      "[40]\tvalid_0's auc: 0.985911\n",
      "[41]\tvalid_0's auc: 0.985924\n",
      "[42]\tvalid_0's auc: 0.985926\n",
      "[43]\tvalid_0's auc: 0.985937\n",
      "[44]\tvalid_0's auc: 0.985948\n",
      "[45]\tvalid_0's auc: 0.985975\n",
      "[46]\tvalid_0's auc: 0.985982\n",
      "[47]\tvalid_0's auc: 0.985983\n",
      "[48]\tvalid_0's auc: 0.985993\n",
      "[49]\tvalid_0's auc: 0.986015\n",
      "[50]\tvalid_0's auc: 0.985994\n",
      "[51]\tvalid_0's auc: 0.986011\n",
      "[52]\tvalid_0's auc: 0.986038\n",
      "[53]\tvalid_0's auc: 0.986047\n",
      "[54]\tvalid_0's auc: 0.986043\n",
      "[55]\tvalid_0's auc: 0.986048\n",
      "[56]\tvalid_0's auc: 0.986055\n",
      "[57]\tvalid_0's auc: 0.986062\n",
      "[58]\tvalid_0's auc: 0.986063\n",
      "[59]\tvalid_0's auc: 0.98609\n",
      "[60]\tvalid_0's auc: 0.986096\n",
      "[61]\tvalid_0's auc: 0.986095\n",
      "[62]\tvalid_0's auc: 0.986117\n",
      "[63]\tvalid_0's auc: 0.986127\n",
      "[64]\tvalid_0's auc: 0.98611\n",
      "[65]\tvalid_0's auc: 0.986115\n",
      "[66]\tvalid_0's auc: 0.986124\n",
      "[67]\tvalid_0's auc: 0.986118\n",
      "[68]\tvalid_0's auc: 0.986101\n",
      "[69]\tvalid_0's auc: 0.986124\n",
      "[70]\tvalid_0's auc: 0.986122\n",
      "[71]\tvalid_0's auc: 0.986101\n",
      "[72]\tvalid_0's auc: 0.986098\n",
      "[73]\tvalid_0's auc: 0.986103\n",
      "[74]\tvalid_0's auc: 0.986099\n",
      "[75]\tvalid_0's auc: 0.986109\n",
      "[76]\tvalid_0's auc: 0.986112\n",
      "[77]\tvalid_0's auc: 0.986126\n",
      "[78]\tvalid_0's auc: 0.986112\n",
      "[79]\tvalid_0's auc: 0.986111\n",
      "[80]\tvalid_0's auc: 0.986116\n",
      "[81]\tvalid_0's auc: 0.986106\n",
      "[82]\tvalid_0's auc: 0.986109\n",
      "[83]\tvalid_0's auc: 0.986107\n",
      "[84]\tvalid_0's auc: 0.986104\n",
      "[85]\tvalid_0's auc: 0.986105\n",
      "[86]\tvalid_0's auc: 0.986105\n",
      "[87]\tvalid_0's auc: 0.986107\n",
      "[88]\tvalid_0's auc: 0.986117\n",
      "[89]\tvalid_0's auc: 0.986115\n",
      "[90]\tvalid_0's auc: 0.986122\n",
      "[91]\tvalid_0's auc: 0.986127\n",
      "[92]\tvalid_0's auc: 0.98612\n",
      "[93]\tvalid_0's auc: 0.986125\n",
      "[94]\tvalid_0's auc: 0.986116\n",
      "[95]\tvalid_0's auc: 0.986128\n",
      "[96]\tvalid_0's auc: 0.986124\n",
      "[97]\tvalid_0's auc: 0.986129\n",
      "[98]\tvalid_0's auc: 0.986137\n",
      "[99]\tvalid_0's auc: 0.986137\n",
      "[100]\tvalid_0's auc: 0.986143\n",
      "[101]\tvalid_0's auc: 0.986143\n",
      "[102]\tvalid_0's auc: 0.986143\n",
      "[103]\tvalid_0's auc: 0.986148\n",
      "[104]\tvalid_0's auc: 0.98615\n",
      "[105]\tvalid_0's auc: 0.986144\n",
      "[106]\tvalid_0's auc: 0.986149\n",
      "[107]\tvalid_0's auc: 0.986169\n",
      "[108]\tvalid_0's auc: 0.986165\n",
      "[109]\tvalid_0's auc: 0.986171\n",
      "[110]\tvalid_0's auc: 0.986167\n",
      "[111]\tvalid_0's auc: 0.986167\n",
      "[112]\tvalid_0's auc: 0.986167\n",
      "[113]\tvalid_0's auc: 0.986164\n",
      "[114]\tvalid_0's auc: 0.986163\n",
      "[115]\tvalid_0's auc: 0.986163\n",
      "[116]\tvalid_0's auc: 0.986163\n",
      "[117]\tvalid_0's auc: 0.986169\n",
      "[118]\tvalid_0's auc: 0.986174\n",
      "[119]\tvalid_0's auc: 0.986176\n",
      "[120]\tvalid_0's auc: 0.986177\n",
      "[121]\tvalid_0's auc: 0.986184\n",
      "[122]\tvalid_0's auc: 0.986188\n",
      "[123]\tvalid_0's auc: 0.986185\n",
      "[124]\tvalid_0's auc: 0.986181\n",
      "[125]\tvalid_0's auc: 0.986182\n",
      "[126]\tvalid_0's auc: 0.986176\n",
      "[127]\tvalid_0's auc: 0.986171\n",
      "[128]\tvalid_0's auc: 0.986164\n",
      "[129]\tvalid_0's auc: 0.98617\n",
      "[130]\tvalid_0's auc: 0.986177\n",
      "[131]\tvalid_0's auc: 0.98617\n",
      "[132]\tvalid_0's auc: 0.986171\n",
      "[133]\tvalid_0's auc: 0.986164\n",
      "[134]\tvalid_0's auc: 0.986165\n",
      "[135]\tvalid_0's auc: 0.986158\n",
      "[136]\tvalid_0's auc: 0.986157\n",
      "[137]\tvalid_0's auc: 0.986168\n",
      "[138]\tvalid_0's auc: 0.986167\n",
      "[139]\tvalid_0's auc: 0.986169\n",
      "[140]\tvalid_0's auc: 0.986172\n",
      "[141]\tvalid_0's auc: 0.986172\n",
      "[142]\tvalid_0's auc: 0.986168\n",
      "[143]\tvalid_0's auc: 0.986169\n",
      "[144]\tvalid_0's auc: 0.986175\n",
      "[145]\tvalid_0's auc: 0.986176\n",
      "[146]\tvalid_0's auc: 0.986188\n",
      "[147]\tvalid_0's auc: 0.986188\n",
      "[148]\tvalid_0's auc: 0.986189\n",
      "[149]\tvalid_0's auc: 0.986201\n",
      "[150]\tvalid_0's auc: 0.986209\n",
      "[151]\tvalid_0's auc: 0.986218\n",
      "[152]\tvalid_0's auc: 0.986226\n",
      "[153]\tvalid_0's auc: 0.986221\n",
      "[154]\tvalid_0's auc: 0.986229\n",
      "[155]\tvalid_0's auc: 0.986228\n",
      "[156]\tvalid_0's auc: 0.986228\n",
      "[157]\tvalid_0's auc: 0.98623\n",
      "[158]\tvalid_0's auc: 0.986227\n",
      "[159]\tvalid_0's auc: 0.986226\n",
      "[160]\tvalid_0's auc: 0.986223\n",
      "[161]\tvalid_0's auc: 0.986229\n",
      "[162]\tvalid_0's auc: 0.986241\n",
      "[163]\tvalid_0's auc: 0.986249\n",
      "[164]\tvalid_0's auc: 0.986248\n",
      "[165]\tvalid_0's auc: 0.986248\n",
      "[166]\tvalid_0's auc: 0.986251\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b42d59bd9c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#test_data = lgb.Dataset(x_test, label=test_label, reference=train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#bst = lgb.train(param, train_data, num_round)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 平均值模型直接预测概率，不经过模型融合,用于寻找参数\n",
    "param = {\n",
    "    'num_leaves':200, \n",
    "    'num_trees':300, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_threads':10,\n",
    "    'min_sum_hessian_in_leaf':100\n",
    "}\n",
    "\n",
    "kfolds = 10\n",
    "kf = KFold(n_splits=kfolds,shuffle=False,random_state=2016)\n",
    "sample_result = np.zeros((len(y_sample),))\n",
    "i=0\n",
    "num_round = 500\n",
    "for train_index,test_index in kf.split(x_sample):\n",
    "\n",
    "    X_train, X_test = x_sample[train_index], x_sample[test_index]\n",
    "    y_train, y_test = y_sample[train_index], y_sample[test_index]\n",
    "    train_data = lgb.Dataset(X_train,label=y_train)\n",
    "    validation_data = lgb.Dataset(X_test,label=y_test)\n",
    "    #test_data = lgb.Dataset(x_test, label=test_label, reference=train_data)\n",
    "    bst = lgb.train( param,train_data, valid_sets=[validation_data],early_stopping_rounds=100)\n",
    "    break\n",
    "    #bst = lgb.train(param, train_data, num_round)\n",
    "    sample_result[test_index] = bst.predict(X_test)\n",
    "    print('测试误差',mse(y_test,sample_result[test_index]))\n",
    "    nonsample_result[i,:] = bst.predict(x_nonsample)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's auc: 0.983548\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[2]\tvalid_0's auc: 0.98417\n",
      "[3]\tvalid_0's auc: 0.984572\n",
      "[4]\tvalid_0's auc: 0.98473\n",
      "[5]\tvalid_0's auc: 0.984839\n",
      "[6]\tvalid_0's auc: 0.984903\n",
      "[7]\tvalid_0's auc: 0.985061\n",
      "[8]\tvalid_0's auc: 0.985185\n",
      "[9]\tvalid_0's auc: 0.985249\n",
      "[10]\tvalid_0's auc: 0.985306\n",
      "[11]\tvalid_0's auc: 0.985339\n",
      "[12]\tvalid_0's auc: 0.985388\n",
      "[13]\tvalid_0's auc: 0.985429\n",
      "[14]\tvalid_0's auc: 0.985473\n",
      "[15]\tvalid_0's auc: 0.98551\n",
      "[16]\tvalid_0's auc: 0.985535\n",
      "[17]\tvalid_0's auc: 0.985549\n",
      "[18]\tvalid_0's auc: 0.985573\n",
      "[19]\tvalid_0's auc: 0.985559\n",
      "[20]\tvalid_0's auc: 0.985578\n",
      "[21]\tvalid_0's auc: 0.98559\n",
      "[22]\tvalid_0's auc: 0.985569\n",
      "[23]\tvalid_0's auc: 0.985595\n",
      "[24]\tvalid_0's auc: 0.985581\n",
      "[25]\tvalid_0's auc: 0.985602\n",
      "[26]\tvalid_0's auc: 0.985613\n",
      "[27]\tvalid_0's auc: 0.985628\n",
      "[28]\tvalid_0's auc: 0.985675\n",
      "[29]\tvalid_0's auc: 0.985713\n",
      "[30]\tvalid_0's auc: 0.985733\n",
      "[31]\tvalid_0's auc: 0.98573\n",
      "[32]\tvalid_0's auc: 0.985765\n",
      "[33]\tvalid_0's auc: 0.985772\n",
      "[34]\tvalid_0's auc: 0.985789\n",
      "[35]\tvalid_0's auc: 0.985782\n",
      "[36]\tvalid_0's auc: 0.985798\n",
      "[37]\tvalid_0's auc: 0.985792\n",
      "[38]\tvalid_0's auc: 0.985792\n",
      "[39]\tvalid_0's auc: 0.985781\n",
      "[40]\tvalid_0's auc: 0.985759\n",
      "[41]\tvalid_0's auc: 0.98576\n",
      "[42]\tvalid_0's auc: 0.985779\n",
      "[43]\tvalid_0's auc: 0.9858\n",
      "[44]\tvalid_0's auc: 0.985796\n",
      "[45]\tvalid_0's auc: 0.985787\n",
      "[46]\tvalid_0's auc: 0.985804\n",
      "[47]\tvalid_0's auc: 0.985805\n",
      "[48]\tvalid_0's auc: 0.98582\n",
      "[49]\tvalid_0's auc: 0.985823\n",
      "[50]\tvalid_0's auc: 0.98584\n",
      "[51]\tvalid_0's auc: 0.985845\n",
      "[52]\tvalid_0's auc: 0.985869\n",
      "[53]\tvalid_0's auc: 0.985879\n",
      "[54]\tvalid_0's auc: 0.985893\n",
      "[55]\tvalid_0's auc: 0.985901\n",
      "[56]\tvalid_0's auc: 0.985919\n",
      "[57]\tvalid_0's auc: 0.985903\n",
      "[58]\tvalid_0's auc: 0.985902\n",
      "[59]\tvalid_0's auc: 0.98591\n",
      "[60]\tvalid_0's auc: 0.985934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-04bdbd323a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m#test_data = lgb.Dataset(x_test, label=test_label, reference=train_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m#bst = lgb.train(param, train_data, num_round)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 直接预测概率，不经过模型融合,用于寻找参数\n",
    "param = {\n",
    "    'num_leaves':200, \n",
    "    'num_trees':300, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_threads':10,\n",
    "    'min_sum_hessian_in_leaf':100\n",
    "}\n",
    "\n",
    "kfolds = 10\n",
    "kf = KFold(n_splits=kfolds,shuffle=False,random_state=2016)\n",
    "sample_result = np.zeros((len(y_sample),))\n",
    "i=0\n",
    "num_round = 500\n",
    "for train_index,test_index in kf.split(x_sample):\n",
    "\n",
    "    X_train, X_test = x_sample[train_index], x_sample[test_index]\n",
    "    y_train, y_test = y_sample[train_index], y_sample[test_index]\n",
    "    train_data = lgb.Dataset(X_train,label=y_train)\n",
    "    validation_data = lgb.Dataset(X_test,label=y_test)\n",
    "    #test_data = lgb.Dataset(x_test, label=test_label, reference=train_data)\n",
    "    bst = lgb.train( param,train_data, valid_sets=[validation_data],early_stopping_rounds=100)\n",
    "    break\n",
    "    #bst = lgb.train(param, train_data, num_round)\n",
    "    sample_result[test_index] = bst.predict(X_test)\n",
    "    print('测试误差',mse(y_test,sample_result[test_index]))\n",
    "    nonsample_result[i,:] = bst.predict(x_nonsample)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# \n",
    "param = {\n",
    "    'num_leaves':200, \n",
    "    'num_trees':250, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_threads':10,\n",
    "    'min_sum_hessian_in_leaf':100\n",
    "}\n",
    "train_data = lgb.Dataset(x_sample,label=y_sample)\n",
    "bst = lgb.train(param,train_data)\n",
    "bst.save_model('layer_1_model_1_prob.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-99a23ace1fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_sample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_sample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mbst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'layer_1_model_2_ave_prob.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    199\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1519\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "# \n",
    "param = {\n",
    "    'num_leaves':200, \n",
    "    'num_trees':250, \n",
    "    'objective':'binary',\n",
    "    'metric':'auc',\n",
    "    'learning_rate': 0.1,\n",
    "    'num_threads':10,\n",
    "    'min_sum_hessian_in_leaf':100\n",
    "}\n",
    "train_data = lgb.Dataset(x_sample,label=y_sample)\n",
    "bst = lgb.train(param,train_data)\n",
    "bst.save_model('layer_1_model_2_ave_prob.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.Booster(model_file='layer_1_model_2_ave_prob.txt') \n",
    "predict_x = np.load('X_test_ave.npy')\n",
    "predict_prob = bst.predict(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测输出，初步预测输出\n",
    "predict_x = np.load('layer_3_basicinfo.npy')\n",
    "predict_prob = bst.predict(predict_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存数据到pickle\n",
    "i = 0\n",
    "x_max = 548\n",
    "y_max = 421\n",
    "weather = {}\n",
    "for day in range(1,6):\n",
    "    weather_h = {}\n",
    "    for h in range(3,21):\n",
    "        data = np.zeros((x_max,y_max),np.float16)\n",
    "        for x in range(x_max):\n",
    "            for y in range(y_max):\n",
    "                data[x,y] = predict_prob[i]\n",
    "                i += 1\n",
    "        weather_h[str(h)] = data\n",
    "    weather[str(day)] = weather_h\n",
    "import pickle\n",
    "f1 = open('layer_1_output_prob_ave.pkl', 'wb')\n",
    "pickle.dump(weather,f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    #bst = lgb.train(param,train_data,valid_sets=validation_data,early_stopping_rounds=50)\n",
    "    # best result 3.307\n",
    "    #break\n",
    "    #xg_train = xgb.DMatrix(X_train, label = y_train)  \n",
    "    #xgeval = xgb.DMatrix(X_test,label=y_test)\n",
    "    #watchlist = [(xg_train, 'train'), (xgeval, 'val')]\n",
    "    #bst2 = xgb.train(param, xg_train, num_round,watchlist, early_stopping_rounds = 100)\n",
    "    # best result smaller than 2.2 in 62 rounds\n",
    "    #break\n",
    "    # mse\n",
    "    #print('训练误差',mse(y_train,bst.predict(xg_train)))\n",
    "    #predict_x = xgb.DMatrix(np.array(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.8381299   12.67829644  12.49357571  12.62091972  13.11059302\n",
      "   15.4390915   15.41172877  15.35912885  13.04983685]\n",
      " [ 12.79528249  12.68653863  12.40559759  12.69644404  13.05902716\n",
      "   15.18816091  15.1470643   15.13895261  13.05516924]\n",
      " [ 12.77775689  12.66773553  12.48897243  12.63885546  13.555559\n",
      "   15.40350466  15.33537203  15.26145667  13.06803193]\n",
      " [ 12.84612792  12.62040606  12.07626445  12.46056851  13.323624\n",
      "   15.00568061  14.9951347   14.99411874  13.18976548]\n",
      " [ 12.93796562  12.79704992  12.74291576  12.65589549  13.18260743\n",
      "   14.90393838  14.927097    15.01066666  13.00541304]\n",
      " [ 12.98128649  12.72400224  12.3574961   12.8301991   13.14539873\n",
      "   15.07529364  15.05802388  15.00805135  13.24577298]\n",
      " [ 12.86725314  12.78413363  12.3315796   12.53764423  13.10881684\n",
      "   15.03923253  15.00455467  14.8898428   13.2399174 ]\n",
      " [ 12.8728845   12.7088336   12.53070187  12.89741614  13.07289398\n",
      "   15.15279661  15.11160781  15.0317126   13.13704855]\n",
      " [ 12.65139305  12.4789665   12.32451026  12.39677926  13.06754261\n",
      "   15.13968306  15.20776205  15.06345853  13.30308718]\n",
      " [ 12.94894843  12.55299748  12.63155967  12.80271669  13.50398474\n",
      "   15.20071123  15.02828884  14.93470757  13.26201251]]\n",
      "[ 12.54821367  12.68253901  12.92302171  12.37749514  12.10771531\n",
      "  12.15057187  12.50978615  12.63368015  14.99482677  15.7571493 ]\n"
     ]
    }
   ],
   "source": [
    "print(nonsample_result[:,1:10])\n",
    "print(sample_result[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonsample_wind = nonsample_result.mean(axis=0)\n",
    "i = 0\n",
    "for item in index_nonsample:\n",
    "    train_y[item] = nonsample_wind[i]\n",
    "    i += 1\n",
    "j = 0\n",
    "for item in index_sample:\n",
    "    train_y[item] = sample_result[j]\n",
    "    j += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"layer_1_gbm_output.npy\", train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "output_weather = open('weather_output.pkl', 'rb')\n",
    "output_weather = pickle.load(output_weather)\n",
    "i = 0\n",
    "x_max = 548\n",
    "y_max = 421\n",
    "for day in range(1,6):\n",
    "    print(day)\n",
    "    for h in range(3,21):\n",
    "        for x in range(x_max):\n",
    "            for y in range(y_max):\n",
    "                output_weather[str(day)][str(h)][x][y] = np.float16(train_y[i])\n",
    "                i += 1\n",
    "import pickle\n",
    "f1 = open('layer_2_gbm_input.pkl', 'wb')\n",
    "pickle.dump(output_weather,f1)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_result[test_index][1000:2000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 30.6 ,  31.3 ,  31.9 ,  32.3 ,  32.6 ,  32.5 ,  32.2 ,  31.7 ,\n",
       "        31.8 ,  32.  ,  32.6 ,  32.8 ,  32.7 ,  32.8 ,  32.6 ,  32.3 ,\n",
       "        31.4 ,  30.7 ,  30.6 ,  30.9 ,  31.2 ,   3.12,   3.02,   2.53,\n",
       "         1.15,   2.12,   4.1 ,   3.25,   1.27,   1.45,   0.7 ,   0.45,\n",
       "         0.27,   0.87,   1.07,   1.9 ,   1.15,   1.06,   1.42,   1.73,\n",
       "         1.52,   2.37,   2.52,   2.67,   2.46,   2.87,   4.52,   4.8 ,\n",
       "         6.4 ,   6.56,   7.16,   7.2 ,   7.7 ,   7.73,   8.4 ,   8.77,\n",
       "         9.11,   9.33,   9.39,  11.4 ,  10.2 ,   9.85,  10.6 ,  10.8 ,\n",
       "        10.8 ,  10.8 ,  11.  ,  10.9 ,  11.4 ,  12.8 ,  13.1 ,  13.1 ,\n",
       "        13.1 ,  13.4 ,  14.  ,  13.8 ,  13.8 ,  13.8 ,  14.3 ,  14.6 ,\n",
       "        14.7 ,  14.7 ,  14.9 ,  15.4 ,  16.2 ,  17.  ,  17.4 ,  17.6 ,\n",
       "        17.4 ,  17.  ,  16.5 ,  16.4 ,  16.6 ,  16.7 ,  16.6 ,  16.7 ,\n",
       "        16.1 ,  15.6 ,  15.8 ,  15.8 ,  14.9 ,  14.3 ,  14.  ,  13.8 ,\n",
       "        14.2 ,  15.6 ,  17.2 ,  18.3 ,  18.6 ,  18.3 ,  18.  ,  17.9 ,\n",
       "        17.7 ,  17.5 ,  17.5 ,  17.4 ,  17.7 ,  17.8 ,  17.8 ,  17.7 ,\n",
       "        17.7 ,  17.9 ,  18.  ,  18.2 ,  18.4 ,  18.8 ,  19.4 ,  19.6 ,\n",
       "        19.9 ,  20.2 ,  20.1 ,  20.2 ,  20.6 ,  21.1 ,  20.7 ,  20.9 ,\n",
       "        20.6 ,  20.6 ,  20.6 ,  21.  ,  21.2 ,  21.6 ,  22.  ,  22.3 ,\n",
       "        22.5 ,  22.7 ,  22.8 ,  22.2 ,  22.6 ,  23.2 ,  22.7 ,  22.3 ,\n",
       "        21.3 ,  21.3 ,  22.7 ,  23.4 ,  22.6 ,  22.3 ,  22.3 ,  22.5 ,\n",
       "        22.5 ,  23.7 ,  24.3 ,  24.8 ,  25.3 ,  25.  ,  25.3 ,  25.7 ,\n",
       "        25.8 ,  26.  ,  26.2 ,  26.3 ,  26.4 ,  26.1 ,  25.8 ,  26.  ,\n",
       "        26.2 ,  26.6 ,  27.  ,  27.  ,  26.9 ,  26.8 ,  27.  ,  27.5 ,\n",
       "        28.1 ,  28.2 ,  28.3 ,  28.2 ,  28.4 ,  28.8 ,  29.  ,  28.5 ,\n",
       "        27.7 ,  27.5 ,  27.9 ,  28.6 ,  29.2 ,  29.5 ,  29.7 ,  29.9 ,\n",
       "        29.9 ,  30.1 ,  30.4 ,  30.7 ,  30.7 ,  30.5 ,  30.3 ,  30.1 ,\n",
       "        30.  ,  30.1 ,  30.2 ,  30.5 ,  30.7 ,  29.8 ,  28.9 ,  28.5 ,\n",
       "        28.3 ,  28.3 ,  28.4 ,  28.5 ,  28.6 ,  28.6 ,  28.7 ,  28.7 ,\n",
       "        28.9 ,  29.  ,  29.4 ,  29.9 ,  30.4 ,  30.4 ,  30.5 ,  30.7 ,\n",
       "        31.2 ,  32.  ,  32.6 ,  33.1 ,  33.6 ,  34.1 ,  34.2 ,  34.5 ,\n",
       "        34.5 ,  34.5 ,  34.5 ,  34.4 ,  34.2 ,  33.9 ,  33.6 ,  33.5 ,\n",
       "        33.3 ,  32.9 ,  32.1 ,  31.4 ,  30.7 ,  30.  ,  29.  ,  28.  ,\n",
       "        28.1 ,  28.1 ,  27.5 ,  26.9 ,  26.9 ,  27.2 ,  27.7 ,  28.3 ,\n",
       "        28.9 ,  29.  ,  28.6 ,  28.  ,  27.4 ,  27.4 ,  28.1 ,  29.2 ,\n",
       "        30.3 ,  31.4 ,  32.1 ,  32.5 ,  32.6 ,  32.5 ,  32.  ,  31.6 ,\n",
       "        31.5 ,  31.8 ,  32.  ,  32.  ,  32.4 ,  32.5 ,  31.9 ,  30.9 ,\n",
       "        30.3 ,  30.5 ,  31.  ,  31.1 ,   3.36,   1.84,   2.91,   3.75,\n",
       "         2.46,   1.9 ,   3.02,   2.74,   1.25,   1.25,   0.76,   0.63,\n",
       "         1.41,   1.91,   2.51,   6.32,   6.99,   7.44,   7.47,   8.3 ,\n",
       "         9.05,  10.  ,  12.1 ,  10.1 ,  10.9 ,  11.  ,  13.2 ,  13.4 ,\n",
       "        13.4 ,  13.4 ,  13.4 ,  13.7 ,  13.8 ,  13.9 ,  14.5 ,  14.8 ,\n",
       "        14.8 ,  14.7 ,  14.9 ,  15.7 ,  16.7 ,  17.8 ,  18.5 ,  18.6 ,\n",
       "        17.7 ,  16.3 ,  15.6 ,  15.7 ,  15.8 ,  15.1 ,  14.5 ,  16.2 ,\n",
       "        17.8 ,  18.5 ,  17.6 ,  15.9 ,  14.8 ,  14.4 ,  14.1 ,  14.1 ,\n",
       "        14.7 ,  15.7 ,  16.4 ,  16.8 ,  17.2 ,  17.3 ,  17.3 ,  17.4 ,\n",
       "        17.5 ,  17.6 ,  17.7 ,  17.7 ,  17.8 ,  18.  ,  18.  ,  18.  ,\n",
       "        18.1 ,  18.3 ,  18.5 ,  19.  ,  19.5 ,  19.6 ,  20.  ,  20.2 ,\n",
       "        20.5 ,  20.3 ,  20.6 ,  21.  ,  21.1 ,  21.4 ,  21.  ,  20.9 ,\n",
       "        21.1 ,  21.5 ,  21.7 ,  22.1 ,  22.3 ,  22.6 ,  23.  ,  22.8 ,\n",
       "        22.8 ,  22.5 ,  22.5 ,  22.8 ,  23.  ,  22.9 ,  23.2 ,  23.7 ,\n",
       "        24.4 ,  24.4 ,  24.2 ,  24.1 ,  24.3 ,  24.1 ,  23.6 ,  23.7 ,\n",
       "        24.1 ,  25.2 ,  25.7 ,  24.6 ,  24.5 ,  25.1 ,  25.3 ,  25.8 ,\n",
       "        26.2 ,  26.6 ,  26.5 ,  26.4 ,  26.3 ,  26.4 ,  26.8 ,  27.  ,\n",
       "        27.1 ,  27.  ,  26.8 ,  26.6 ,  26.7 ,  27.5 ,  28.2 ,  28.4 ,\n",
       "        28.2 ,  28.1 ,  28.5 ,  29.2 ,  29.3 ,  28.7 ,  28.1 ,  28.1 ,\n",
       "        28.5 ,  29.1 ,  29.4 ,  29.5 ,  29.8 ,  29.8 ,  29.9 ,  30.1 ,\n",
       "        30.4 ,  30.6 ,  30.5 ,  30.3 ,  30.2 ,  30.  ,  29.8 ,  29.8 ,\n",
       "        29.9 ,  30.3 ,  30.8 ,  30.6 ,  29.5 ,  29.  ,  28.9 ,  28.7 ,\n",
       "        28.6 ,  28.6 ,  28.6 ,  28.6 ,  28.5 ,  28.4 ,  28.6 ,  28.8 ,\n",
       "        29.1 ,  29.6 ,  30.  ,  30.2 ,  30.4 ,  30.5 ,  30.7 ,  31.3 ,\n",
       "        32.2 ,  32.8 ,  33.3 ,  33.8 ,  34.2 ,  34.5 ,  34.8 ,  34.9 ,\n",
       "        34.9 ,  34.9 ,  34.8 ,  34.5 ,  34.2 ,  33.9 ,  33.7 ,  33.5 ,\n",
       "        32.8 ,  32.1 ,  31.5 ,  31.2 ,  30.3 ,  29.  ,  28.1 ,  28.4 ,\n",
       "        28.4 ,  27.9 ,  27.5 ,  27.3 ,  27.5 ,  27.6 ,  28.2 ,  29.2 ,\n",
       "        29.8 ,  29.9 ,  29.1 ,  27.9 ,  27.5 ,  28.1 ,  29.5 ,  31.  ,\n",
       "        32.1 ,  32.5 ,  32.5 ,  32.3 ,  31.9 ,  31.3 ,  31.  ,  31.  ,\n",
       "        31.4 ,  31.6 ,  31.9 ,  32.1 ,  31.6 ,  30.7 ,  30.3 ,  30.7 ,\n",
       "        30.8 ,  30.8 ,   3.09,   1.84,   2.51,   2.32,   2.34,   1.9 ,\n",
       "         2.22,   0.63,   1.17,   1.64,   1.95,   1.76,   2.61,   2.57,\n",
       "         2.75,   3.28,   3.55,   3.72,   3.98,   5.52,   6.83,   7.55,\n",
       "         8.06,   7.81,   7.73,   7.73,   8.47,   8.7 ,   9.02,  10.1 ,\n",
       "        10.9 ,  12.4 ,   9.73,  10.7 ,  10.7 ,  11.1 ,  12.9 ,  13.3 ,\n",
       "        13.4 ,  13.5 ,  13.5 ,  13.6 ,  13.5 ,  13.6 ,  13.7 ,  13.8 ,\n",
       "        14.1 ,  14.2 ,  14.6 ,  14.9 ,  15.  ,  15.  ,  14.9 ,  14.7 ,\n",
       "        14.6 ,  15.4 ,  16.1 ,  16.  ,  15.2 ,  14.9 ,  14.9 ,  14.7 ,\n",
       "        14.8 ,  15.4 ,  15.8 ,  16.  ,  15.7 ,  15.5 ,  15.8 ,  16.2 ,\n",
       "        16.6 ,  16.6 ,  15.9 ,  15.2 ,  14.9 ,  14.9 ,  14.9 ,  15.2 ,\n",
       "        15.7 ,  16.  ,  16.5 ,  16.9 ,  17.3 ,  17.6 ,  17.7 ,  17.9 ,\n",
       "        18.  ,  18.1 ,  18.2 ,  18.2 ,  18.5 ,  18.6 ,  18.7 ,  18.8 ,\n",
       "        19.2 ,  19.3 ,  19.4 ,  19.6 ,  20.  ,  20.2 ,  20.5 ,  20.5 ,\n",
       "        20.7 ,  20.9 ,  20.9 ,  20.9 ,  21.  ,  21.3 ,  21.5 ,  21.2 ,\n",
       "        21.5 ,  21.8 ,  22.1 ,  22.6 ,  23.1 ,  23.1 ,  22.6 ,  22.2 ,\n",
       "        22.1 ,  22.2 ,  22.3 ,  22.4 ,  22.9 ,  23.  ,  23.  ,  23.2 ,\n",
       "        23.4 ,  23.3 ,  23.7 ,  23.7 ,  23.5 ,  23.7 ,  24.2 ,  24.9 ,\n",
       "        25.4 ,  25.  ,  24.7 ,  24.8 ,  24.5 ,  24.4 ,  24.6 ,  25.2 ,\n",
       "        25.8 ,  26.1 ,  26.5 ,  26.7 ,  26.9 ,  27.  ,  27.  ,  27.1 ,\n",
       "        26.9 ,  26.5 ,  26.7 ,  27.6 ,  28.3 ,  28.6 ,  28.3 ,  28.4 ,\n",
       "        28.9 ,  29.5 ,  29.6 ,  29.2 ,  28.6 ,  28.5 ,  28.8 ,  29.3 ,\n",
       "        29.6 ,  29.8 ,  29.9 ,  29.9 ,  29.9 ,  30.1 ,  30.2 ,  30.3 ,\n",
       "        30.3 ,  30.1 ,  30.  ,  29.8 ,  29.5 ,  29.4 ,  29.5 ,  30.2 ,\n",
       "        30.8 ,  30.8 ,  30.3 ,  29.7 ,  29.4 ,  29.2 ,  28.9 ,  28.8 ,\n",
       "        28.8 ,  28.7 ,  28.4 ,  28.4 ,  28.4 ,  28.5 ,  28.8 ,  29.2 ,\n",
       "        29.7 ,  30.1 ,  30.2 ,  30.3 ,  30.3 ,  30.6 ,  31.4 ,  32.4 ,\n",
       "        33.  ,  33.4 ,  33.8 ,  34.3 ,  34.8 ,  35.1 ,  35.2 ,  35.3 ,\n",
       "        35.3 ,  35.1 ,  34.7 ,  34.3 ,  34.1 ,  33.9 ,  33.5 ,  32.8 ,\n",
       "        32.1 ,  31.8 ,  30.9 ,  29.5 ,  28.3 ,  28.2 ,  28.9 ,  28.6 ,\n",
       "        27.8 ,  27.5 ,  27.5 ,  27.7 ,  28.2 ,  28.9 ,  30.  ,  30.7 ,\n",
       "        30.7 ,  29.5 ,  28.6 ,  28.6 ,  29.6 ,  30.8 ,  31.8 ,  32.1 ,\n",
       "        32.1 ,  31.8 ,  31.3 ,  31.1 ,  31.  ,  30.8 ,  30.9 ,  31.1 ,\n",
       "        31.3 ,  31.5 ,  31.2 ,  30.6 ,  30.5 ,  30.8 ,  30.5 ,  30.4 ,\n",
       "         2.74,   2.12,   2.57,   2.8 ,   1.62,   2.05,   2.5 ,   1.45,\n",
       "         1.06,   0.88,   0.51,   0.83,   0.88,   1.11,   1.42,   1.97,\n",
       "         2.37,   2.25,   2.63,   2.69,   2.64,   2.62,   2.57,   2.67,\n",
       "         2.65,   3.1 ,   3.82,   3.98,   4.06,   3.89,   3.55,   3.8 ,\n",
       "         6.32,   6.91,   7.26,   8.02,   8.43,   9.86,  10.  ,  10.8 ,\n",
       "         9.06,   7.38,   8.81,   9.55,  10.  ,  10.7 ,  10.9 ,  11.2 ,\n",
       "        11.4 ,  12.3 ,  12.8 ,  13.5 ,  13.7 ,  13.9 ,  13.9 ,  13.9 ,\n",
       "        14.2 ,  14.7 ,  14.8 ,  15.  ,  15.2 ,  15.3 ,  15.3 ,  15.1 ,\n",
       "        14.8 ,  14.9 ,  15.1 ,  15.7 ,  16.5 ,  17.5 ,  18.2 ,  18.6 ,\n",
       "        18.9 ,  19.  ,  18.9 ,  18.7 ,  17.3 ,  15.7 ,  15.2 ,  15.4 ,\n",
       "        15.9 ,  16.2 ,  16.3 ,  16.2 ,  16.  ,  15.9 ,  15.7 ,  15.6 ,\n",
       "        15.7 ,  15.9 ,  16.5 ,  17.1 ,  17.6 ,  17.9 ,  18.  ,  18.  ,\n",
       "        18.1 ,  18.3 ,  18.4 ,  18.5 ,  18.6 ,  18.6 ,  18.7 ,  18.9 ,\n",
       "        18.9 ,  19.1 ,  19.3 ,  19.4 ,  19.7 ,  20.  ,  20.3 ,  20.5 ,\n",
       "        20.5 ,  20.8 ,  20.9 ,  20.8 ,  20.9 ,  21.  ,  21.4 ,  21.5 ,\n",
       "        21.4 ,  21.6 ,  21.8 ,  22.1 ,  22.5 ,  22.8 ,  23.6 ,  23.2 ,\n",
       "        23.1 ,  22.9 ,  22.9 ,  22.9 ,  23.1 ,  23.4 ,  23.3 ,  23.2 ,\n",
       "        23.1 ,  23.  ,  22.7 ,  23.3 ,  23.7 ,  23.8 ,  24.1 ,  24.8 ,\n",
       "        25.1 ,  25.5 ,  25.8 ,  26.4 ,  26.8 ,  26.7 ,  25.8 ,  24.7 ,\n",
       "        24.1 ,  24.3 ,  24.9 ,  25.6 ,  26.  ,  26.3 ,  26.7 ,  27.  ,\n",
       "        27.2 ,  27.  ,  26.7 ,  26.9 ,  27.7 ,  28.5 ,  28.6 ,  28.5 ,\n",
       "        28.6 ,  29.2 ,  29.8 ,  30.  ,  29.7 ,  29.3 ,  28.9 ,  29.  ,\n",
       "        29.4 ,  29.8 ,  30.  ,  30.1 ,  30.1 ,  30.  ,  30.1 ,  30.1 ,\n",
       "        30.  ,  29.9 ,  29.9 ,  29.7 ,  29.5 ,  29.2 ,  29.1 ,  29.3 ,\n",
       "        30.  ,  30.5 ,  30.7 ,  30.7 ,  30.4 ,  30.1 ,  29.7 ,  29.4 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1000:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试误差 4.361824894\n"
     ]
    }
   ],
   "source": [
    "print('测试误差',mse(y_test,bst.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:02<00:00,  6.61it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.89it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.52it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.77it/s]\n",
      "100%|██████████| 18/18 [00:02<00:00,  6.73it/s]\n"
     ]
    }
   ],
   "source": [
    "input_weather_ave = open('weather_average_input.pkl', 'rb')\n",
    "input_weather_ave = pickle.load(input_weather_ave)\n",
    "input_y_ave = feature_selection_y(input_weather_ave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均值法误差 4.58640380251\n"
     ]
    }
   ],
   "source": [
    "print('平均值法误差',mse(train_y,input_y_ave))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = lgb.train( param,train_data, valid_sets=[test_data],early_stopping_rounds=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
